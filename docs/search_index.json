[["index.html", "Toutes les méthodes du master Introduction", " Toutes les méthodes du master KF Introduction ## packages à charger, nécessaire pour l&#39;analyse ## library(tidyverse) library(questionr) # pour effectuer des tris à plat et des tris croisés library(survey) # pour travailler avec des données pondérées library(glm2) # pour effectuer régressions logistiques library(nnet) # pour effectuer régressions logistiques polytomiques library(GDAtools) "],["stat-desc.html", "Statistiques descriptives", " Statistiques descriptives On importe les données puis on les observe. Ci-dessous jai mis des fonctions de bases avec un dataframe qui nexiste pas. dim(d) names(d) str(d) sum(is.na(d)) summary(d$x) unique(d$x) table(d$x,d$y,useNA=&quot;ifany&quot;) prop.table(table(d$x,d$y,useNA=&quot;ifany&quot;)) rprop(table(d$x,d$y)) # corrélation cor(d$x,d$y,method=&#39;pearson&#39;) # test du khi-deux chisq.test(d$x, d$y) "],["nettoyage.html", "Nettoyage des données", " Nettoyage des données On nettoie les données en prévision des régressions futures (notamment : on dichotomise les modalités des variables explicatives pour les régressions logistiques [codage disjonctif complet - JD recommandait ça, mais on a établi que R arrivait à dichotomiser les modalités des variables comme un grand.]) Par exemple : On a une variable couleur qui prend comme \\(n\\) modalités 1 = bleu ; 2 = blanc ; 3 = rouge. On va la transformer en \\(n-1\\) variables (dans ce cas, 2) binaires, une indiquant si cest bleu (0 = non ; 1 = oui), une indiquant si cest blanc (idem). Il ny a pas besoin de créer une troisième variable dichotomique car, par défaut, une observation qui est à bleu = 0 et blanc = 0 serait à rouge = 1 [nb. jutilise tidyverse mais je te mets dabord la méthode de JD]: d$bleu[d$couleur==1] &lt;- 1 d$bleu[d$couleur!=1] &lt;- 0 d$blanc[d$couleur==2] &lt;- 1 d$blanc[d$couleur!=2] &lt;- 0 # moi je ferais d &lt;- d %&gt;% mutate(bleu = ifelse(couleur==1,1,0), blanc = ifelse(couleur==2,1,0)) En gros, pour une variable à \\(n\\) modalités/catégories que tu veux utiliser dans une régression, tu génères \\(n-1\\) variables dichotomiques. Toutefois, ce nest pas du tout nécessaire parce que les fonctions de régressions de R dichotomisent automatiquement les modalités des variables catégorielles :) Si tu as une variable à \\(n\\) modalités, tu peux aussi choisir de regrouper deux modas ensemble et de les coder en 0 et le reste des modas en 1. Important : une fois que tu as déterminé toutes tes variables explicatives, transforme les en facteur et change leur niveau. Les régressions fonctionnent avec des variables facteurs. Exemple : une variable des mentions du bac qui est à lorigine sous la forme caractère. Les mentions seront rangées par ordre alphabétique et non par ordre hiérachique. d$mentions &lt;- factor(d$mentions, levels=c(&#39;Sans mention&#39;,&#39;Passable&#39;,&#39;Assez bien&#39;,&#39;Bien&#39;,&#39;Très bien&#39;)) "],["reg-lin.html", "1 Régressions linéaires (cours de JD)", " 1 Régressions linéaires (cours de JD) \\[Y_i = \\beta_0 + \\beta_1X_i + \\epsilon_i\\] pour \\(i = 1,...,n\\) La régression linéaire prend comme variable dépendante/à expliquer (\\(var\\_dep\\)) une variable quantitative continue, telle que la température, le PIB, mon envie de dormir progressive pendant les cours dEQles variables explicatives/indépendantes peuvent être quanti ou quali. Tu lis les coefficients de la régression de la manière suivante : toutes choses égales par ailleurs, pour une unité de \\(x\\) (\\(var\\_indep\\)) en plus, \\(y\\) (\\(var\\_dep\\)) augmente/diminue de {coefficient} ou bien toutes choses égales par ailleurs, pour un changement de catégorie de \\(x\\), \\(y\\) augmente/diminue de {coefficient}. # régression linéaire simple (une seule var indep) model_1 &lt;- lm(var_dep ~ var_indep, data = d) summary(model_1) # pour observer le modèle (coefficients, p.value [Pr(&gt;|z|)], deviance, etc.) # pour visualiser la régression plot(d$var_dep, d$var_indep) abline(model_1) On interprète seulement les coefficients statistiquement significatifs (avec des petites étoiles) : un coefficient statistiquement significatif veut dire quon peut rejeter lhypothèse que la variable explicative ninfluence pas la variable à expliquer. Toutefois ça peut être intéressant de dire je suis surprise que cette variable nest pas deffet, ce qui va à lencontre de mon hypothèse/de la littérature, blabla. # régression linéraire multiple (plusieurs var indeps) sans interaction model_2 &lt;- lm(var_dep ~ var_indep1 + var_indep2 + var_indep3, data = d) # si on souhaite obtenir un modèle pondéré model_3 &lt;- lm(var_dep ~ var_indep1 + var_indep2 + var_indep3, data = d, weights = poids) # on peut aussi &quot;mettre à jour&quot; le modèle 2 model_3 &lt;- update(model_2, . ~ ., weights=poids) # régression linéaire multiple avec interaction model_4 &lt;- lm(var_dep ~ var_indep1 + var_indep2 + var_indep3 + var_indep1*var_indep2, data = d, weights = poids) # ou model_4 &lt;- update(model_3, . ~ . + var_indep1*var_indep2) Le coefficient dinteraction sadditionne aux coefficients de base des catégories qui correspondent à ce nouveau coef. Par exemple, on interagit le PIB avec le taux de natalité. Tu obtiens les résultats suivants : - \\(\\beta_1\\) le coefficient du PIB; - \\(\\beta_2\\) le coefficient du taux de natalité; - \\(\\beta_3\\) le coefficient de linteraction entre les deux variables. Pour obtenir le vrai effet du PIB et du taux de natalité sur la \\(var\\_dep\\), tu additionnes ces trois coefficients. Cependant en sociologie, il est rare davoir une variable continue à expliquer. On a généralement des variables catégorielles (qui peuvent être une variable quanti transformée en variable quali). Le modèle de régression linéaire ne fonctionne plus dans ce cas, on se tourne vers le modèle de régression linéaire de probabilité qui prend comme variable dépendante/à expliquer une variable dichotomique (0/1). La ligne R reste la même, seule la nature de la \\(var\\_dep\\) change. Tu lis le coefficient de cette manière : toutes choses égales par ailleurs, pour une unité de plus/pour un changement de catégorie de \\(x\\), la probabilité que lévènement \\(y=1\\) se passe augmente/diminue [je suis pas sûre de la lecture exacte du coefficient, mais en gros ça fonctionne comme ça.] # régression linéaire de probabilité model_5 &lt;- lm(var_dep_dicho ~ var_indep1 + var_indep2 + var_indep3, data = d, weights = poids) "],["reg-log.html", "2 Régressions logistiques 2.1 Régression logistique dichotomique 2.2 Régression logistique polytomique 2.3 Odds ratio", " 2 Régressions logistiques \\[logit(p) = log(\\frac{p}{1-p}) = \\beta_0 + \\sum_{j=1}^n \\beta_j X_{ij}\\] 2.1 Régression logistique dichotomique Pour une raison qui méchappe parce que je suis pas très fraîche et parce que je sais pas, on nutilise pas le modèle de régression linéaire de probabilité mais plutôt le modèle de régression logistique dichotomique. Pour les coefficients, on parlera de leffet du logit de probabilité que lévènement \\(y=1\\) se passe. On commence par lancer le modèle de régression logistique à effets principaux, ou modèle de lindépendance : model_6 &lt;- glm(var_dep_dicho ~ var_indep1 + var_indep2 + var_indep3, data = d, weights = poids, family=binomial) Petite note sur le modèle de lindépendance totale : cest le modèle dans lequel tu balances tes variables explicatives sans interaction ou association, pour vérifier si les variables sont indépendantes entre elles, càd si [toutes choses égales par ailleurs ^^] elles expliquent le phénomène à elles seules. Cependant, en socio, cest inimaginable que la classe sociale et le sexe agissent indépendamment lun de lautre, cest pour cette raison quon choisirait dintéragir ces variables entre elles. Pour vérifier si les variables sont indépendantes, tu regardes la residual deviance : si cest un nb énorme, direction interaction-ville. # On met le modèle précédent à jour, en inclant des interactions. # pour une unique interaction model_7 &lt;- update(model_6, . ~ . + var_indep1*var_indep2) # pour intéragir toutes les modalités de toutes les variables entre elles (interaction d&#39;ordre 2) model_8 &lt;- glm(var_dep_dicho ~ (var_indep1 + var_indep2 + var_indep3)^2, data = d, weights = poids, family=binomial) # pour intéragir var_indep3 avec var_indep1 et var_indep2 [plus rapide que d&#39;écrire individuellement chaque interaction] model_9 &lt;- glm(var_dep_dicho ~ (var_indep1 + var_indep2)*var_indep3, data = d, weights = poids, family=binomial) Le coefficient dinteraction sadditionne aux coefficients de base des catégories qui correspondent à ce nouveau coef. Par exemple, on interagit le sexe et le niveau de diplôme. Tu obtiens les résultats suivants : - \\(\\beta_1\\) le coefficient pour sexe=1 (par exemple les filles); - \\(\\beta_2\\) le coefficient du niveau de diplôme=1 (par exemple ceux qui ont obtenu une licence); - \\(\\beta_3\\) le coefficient de linteraction entre les deux modalités. Pour obtenir le vrai effet de lobtention de la licence chez les filles sur la \\(var\\_dep\\), tu additionnes ces trois coefficients. Tu ne peux pas additionner le coefficient dinteraction pour les garçons avec licence, ou les filles sans licence. On veut voir si lajout de ces interactions est statistiquement significative (cest la méthode de JD, MP a la sienne que je détaille plus bas). On effectue un test statistique sur linteraction, qui est distribué comme une loi du khi-deux, sur la différence de vraisemblance entre les modèles dindépendance et dinteraction. test &lt;- 2*(logLik(model_7)-logLik(model_6)) [1] # Entre ces deux modèles, il n&#39;y a qu&#39;une variable/modalité en plus, donc le degrée de liberté est de 1 (je sais plus pourquoi). 1-pchisq(test,1) # (test,1), 1 étant le ddl. On obtient la probabilité que linteraction soit due au hasard. Si la valeur est inférieure ou égale à 0.10, on peut rejeter lhypothèse que linteraction soit due au hasard. 2.2 Régression logistique polytomique On a vu la régression logistique dichotomique. Mais pour une variable à expliquer qui contient plus de 2 modalités, on utilise le modèle de régression logistique polytomique. Imaginons que tu ais une variable \\(n\\) à expliquer avec des modalités 1 (modalité de référence), 2 et 3, et une variable \\(m\\) explicative avec des modalités A (modalité de ref), B et C. Tu interpréteras un coefficient ainsi : toutes choses égales par ailleurs, le logit de probabilité que lévènement \\(y=2\\) se produise, par rapport à lévènement \\(y=1\\), pour le groupe B augmente/diminue par rapport au groupe A. Cest une phrase assez dégueulasse. Toutefois cest un modèle de régression sur lequel on ne sest pas attardés lannée dernière donc je nen dis pas plus. Voici la commande pour lancer le modèle. model_10 &lt;- multinom(var_dep_poly ~ var_indep1 + var_indep2 + var_indep3, data=d, weights=poids) 2.3 Odds ratio Passons à un truc dont on parle beaucoup en classe : les odds ratio. Les coefficients dune régression logistique ne sont pas très évidents à interpréter (dans le sens où cest long de dire le logit de probabilité). On passe donc les coefficients logit par la fonction exponentielle, ce qui nous donne les odds ratio (OR). Un OR est la chance quun évènement \\(y=1\\) se passe pour une condition B, par rapport à ce que cet évènement \\(y=1\\) se passe pour une condition A (condition de ref). LOR est compris entre \\([0;+\\infty[\\). Pour un OR compris entre 0 et 1, la chance que le truc se passe pour un groupe B est en fait moindre que la chance quil se passe pour le groupe A, mais on dira quand même lévènement a 0.14 fois plus de chance de se passer pour le groupe B que pour le groupe A. Pour obtenir les coefficients de la régression en OR, on utilise la commande suivante : exp(model_7$coefficients) "],["log-lin.html", "3 Régression log-linéaire (cours de MP) 3.1 Modèle de lindépendance 3.2 Modèles avec interaction 3.3 Analyse de deviance", " 3 Régression log-linéaire (cours de MP) Soit un modèle log-linéaire avec trois variables A, B et C ayant chacune des modalités indexées respectivement par les indices \\(i\\), \\(j\\) et \\(k\\). La table de contingence contient les effectifs notés \\(m_{ijk}\\). Un modèle log-linéaire est une régression sur le log des effectifs dans chacun des cases du tableau de contingence, soit : \\[log(m_{ijk}) = constante + \\\\ margeA_i + margeB_j + margeC_k + \\\\ interactionAB_{ij} + interactionAC_{ik} + interactionBC_{jk} + \\\\ interactionABC_{ijk}\\] Un modèle log-linéaire contient toujours la constante et toutes les marges du tableau de contingence. Puis on peut ensuite ajouter des interactions. Il sagit quasiment toujours de modèles hiérarchiques, càd que, dès lors que lon met une interaction dordre n entre un sous-groupe de variables, toutes les interactions dordre inférieur à n entre les variables de ce sous-groupe sont également incluses dans le modèle. La constante permet destimer leffectif total de la table. Les coefficients \\(margeA_i\\) permettent destimer les effectifs de la \\(i^{ème}\\) ligne de la table, qui correspond à la \\(i^{ème}\\) modalité de A. Résumons les différents modèles de régression quon a vu jusquà maintenant : - régression linéaire simple/multiple : variable à expliquer quantitative, toutes les variables sont dans leurs unités de bases. - régression linéaire de probabilité : variable à expliquer dichotomique, toutes les variables sont dans leurs unités de bases. - régression logistique dichotomique/polytomique : variable à expliquer dichotomique, toutes les variables sont mises à léchelle logarithmique (\\(log(x)\\)). On passe maintenant à la régression log-linéaire, que je résume (techniquement) ainsi : la variable à expliquer est mise à léchelle logarithmique, les variables explicatives restent dans leurs unités de bases. Ce modèle est pratique pour expliquer une évolution exponentielle, par exemple lévolution des cas de coronavirus qui est lente au début, augmente très rapidement dans un interval de temps court, puis plafonne. Je tavoue que jai pas vraiment compris/écouté son cours parfaitement, mais il y a quelque chose avec des tableaux croisés à trois dimensions (jutiliserai lexemple des admissions à Berkeley : \\(admissions*département*sexe\\)). # Les packages et fonctions library(vcd) library(vcdExtra) library(DescTools) # source(&quot;f.util.cours.R&quot;) fonction créée par MP que j&#39;inclus direct ici stat_ajust &lt;- function(...) { list_glm &lt;- enquos(...) noms &lt;- as.character(list_glm) %&gt;% map_chr(~str_sub(.x, start = 2)) list_glm &lt;- map(list_glm, rlang::eval_tidy) return(map2_dfr(list_glm, noms, ~ tibble( model = .y, G2 = .x$deviance, ddl = .x$df.residual, p.value.G2 = 1 - pchisq(.x$deviance, .x$df.residual), dissimilarity = sum(abs(.x$y - .x$fitted.values)) / sum(.x$y) / 2, AIC = .x$aic, BIC = AIC(.x, k = log(sum(.x$y))) ))) } # La base Berkeley &lt;- UCBAdmissions %&gt;% as.data.frame() 3.1 Modèle de lindépendance # Modèle log-linéaire # Modèle de l&#39;indépendance totale M0 &lt;- glm(Freq ~ Gender + Admit + Dept, family = poisson, data = UCBAdmissions) # La différence avec la reg logit est la famille de la distribution. Pour la reg logit, on avait family=binomial, ici on a family=poisson. summary(M0) ## ## Call: ## glm(formula = Freq ~ Gender + Admit + Dept, family = poisson, ## data = UCBAdmissions) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -18.170 -7.719 -1.008 4.734 17.153 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 5.37111 0.03964 135.498 &lt; 2e-16 *** ## GenderFemale -0.38287 0.03027 -12.647 &lt; 2e-16 *** ## AdmitRejected 0.45674 0.03051 14.972 &lt; 2e-16 *** ## DeptB -0.46679 0.05274 -8.852 &lt; 2e-16 *** ## DeptC -0.01621 0.04649 -0.349 0.727355 ## DeptD -0.16384 0.04832 -3.391 0.000696 *** ## DeptE -0.46850 0.05276 -8.879 &lt; 2e-16 *** ## DeptF -0.26752 0.04972 -5.380 7.44e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 2650.1 on 23 degrees of freedom ## Residual deviance: 2097.7 on 16 degrees of freedom ## AIC: 2272.7 ## ## Number of Fisher Scoring iterations: 5 # Residual deviance = 2097.7 on 16 degrees of freedom. Il reste beaucoup trop dinformation à expliquer que le modèle de lindépendance totale nexplique pas, trop pour établir lindépendance entre les variables. On décide alors de mettre à jour le modèle en ajoutant des interactions. 3.2 Modèles avec interaction # une interaction prise en compte M1_GD &lt;- update(M0, . ~ . + Gender:Dept) # choix du département est genré M1_GA &lt;- update(M0, . ~ . + Gender:Admit) # admission discriminante en fonction du sexe M1_AD &lt;- update(M0, . ~ . + Admit:Dept) # départements plus ou moins selectifs # deux interactions M2_GD.GA &lt;- update(M1_GD, . ~ . + Admit:Gender) M2_GD.AD &lt;- update(M1_GD, . ~ . + Admit:Dept) M2_AD.GA &lt;- update(M1_AD, . ~ . + Admit:Gender) # trois interactions d&#39;ordre 2 M3 &lt;- update(M2_GD.AD, . ~ . + Gender:Admit) # une interaction d&#39;ordre 3 = modèle saturé M4 &lt;- update(M0, . ~ . + Gender*Admit*Dept) # sélectivité du département varie selon le sexe Tous les modèles sont stockés dans la mémoire de R, on veut maintenant voir le gain ou la perte dinformation offert.e par chaque nouveau modèle. 3.3 Analyse de deviance anova(M0, M1_GA, M1_AD, M1_GD, M2_AD.GA, M2_GD.GA, M2_GD.AD, M3, M4) ## Analysis of Deviance Table ## ## Model 1: Freq ~ Gender + Admit + Dept ## Model 2: Freq ~ Gender + Admit + Dept + Gender:Admit ## Model 3: Freq ~ Gender + Admit + Dept + Admit:Dept ## Model 4: Freq ~ Gender + Admit + Dept + Gender:Dept ## Model 5: Freq ~ Gender + Admit + Dept + Admit:Dept + Gender:Admit ## Model 6: Freq ~ Gender + Admit + Dept + Gender:Dept + Gender:Admit ## Model 7: Freq ~ Gender + Admit + Dept + Gender:Dept + Admit:Dept ## Model 8: Freq ~ Gender + Admit + Dept + Gender:Dept + Admit:Dept + Gender:Admit ## Model 9: Freq ~ Gender + Admit + Dept + Gender:Admit + Gender:Dept + Admit:Dept + ## Gender:Admit:Dept ## Resid. Df Resid. Dev Df Deviance ## 1 16 2097.67 ## 2 15 2004.22 1 93.45 ## 3 11 1242.35 4 761.87 ## 4 11 877.06 0 365.29 ## 5 10 1148.90 1 -271.84 ## 6 10 783.61 0 365.29 ## 7 6 21.74 4 761.87 ## 8 5 20.20 1 1.53 ## 9 0 0.00 5 20.20 En regardant la dernière colonne, Deviance, on peut voir que les modèles 3 (les départements sont sélectifs) et 7 (les départements sont sélectifs et genrés) sont ceux grâce auxquels on a gagné le plus dinformation. Toutefois entre le modèle 3 et le modèle 7, ce dernier a moins de residual deviance, cest donc le modèle qui expliquerait le mieux la variance des données. Visiblement, la sélectivité des départements et leurs compositions sont des éléments importants à inclure dans la régression. Pourquoi ne pas prendre le modèle 9 ? Parce que le modèle 9 est saturé (toutes les combinaisons dinteractions sont dans le modèle, cest logique que toutes les données soient expliquées.) Revenons en au modèle 7. Comment peut-on sassurer que le gain dinfo est réel et pas dû au hasard (nest pas du bruit)? stat_ajust(M0, M1_GA, M1_AD, M1_GD, M2_AD.GA, M2_GD.GA, M2_GD.AD, M3, M4) ## # A tibble: 9 x 7 ## model G2 ddl p.value.G2 dissimilarity AIC BIC ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M0 2.10e+ 3 16 0 2.60e- 1 2273. 2324. ## 2 M1_GA 2.00e+ 3 15 0 2.57e- 1 2181. 2239. ## 3 M1_AD 1.24e+ 3 11 0 2.13e- 1 1427. 1511. ## 4 M1_GD 8.77e+ 2 11 0 1.69e- 1 1062. 1146. ## 5 M2_AD.GA 1.15e+ 3 10 0 1.89e- 1 1336. 1426. ## 6 M2_GD.GA 7.84e+ 2 10 0 1.56e- 1 971. 1061. ## 7 M2_GD.AD 2.17e+ 1 6 0.00135 1.64e- 2 217. 332. ## 8 M3 2.02e+ 1 5 0.00114 1.67e- 2 217. 339. ## 9 M4 -3.38e-14 0 1 1.81e-15 207. 361. Regardons la colonne p.value.G2: une \\(p.value\\) de 0 est suspicieux, on ne prend pas en compte les modèles qui ont cette valeur ; Dissimilarity : proportion des observations mal classées. Le plus bas, le mieux. De ce fait, le modèle 7 est toujours le meilleur, ce qui est confirmé par son BIC qui est le plus faible de tous les modèles (jsp ce que ça mesure par contre.) [coefficients dun modèle log-linéaire avec interaction peut se retrouver avec une régression logistique dichotomique.] "],["ap-exp.html", "4 Approches expérimentales (cours dOG) 4.1 Expériences aléatoires contrôlées 4.2 Expériences naturelles 4.3 Différences-de-différences (differences-in-differences) 4.4 Régression par discontinuité (Regression discontinuity design) 4.5 Variables instrumentales", " 4 Approches expérimentales (cours dOG) library(lfe) library(AER) library(survival) library(plm) library(lmtest) 4.1 Expériences aléatoires contrôlées 4.1.1 Expérience à essais randomisés contrôlés (randomised controlled trials (RCT) experiments) 4.1.2 Expériences par questionnaire (randomised survey experiment) 4.2 Expériences naturelles 4.3 Différences-de-différences (differences-in-differences) 4.4 Régression par discontinuité (Regression discontinuity design) 4.5 Variables instrumentales "],["an-long.html", "5 Analyses longitudinales 5.1 Pseudo-panels 5.2 Modèles linéaires", " 5 Analyses longitudinales library(plm) 5.1 Pseudo-panels 5.2 Modèles linéaires Modèle de base: \\[y_{i,t} = \\alpha_i + \\beta_i k_{i,t} + \\gamma_i n_{i,t} + \\epsilon_{i,t}\\] Modèle pooled: \\[y_{i,t} = \\alpha + \\beta k_{i,t} + \\gamma n_{i,t} + \\epsilon_{i,t}\\] Modèle à effet fixe: \\[y_{i,t} = \\alpha_i + \\beta k_{i,t} + \\gamma n_{i,t} + \\epsilon_{i,t}\\] "],["analyses-de-réseaux.html", "Analyses de réseaux 5.3 Bases de la théorie 5.4 Structures locales 5.5 Connectivité 5.6 Mesures basiques de cohésion 5.7 Mesures de diversité 5.8 Mesures de centralité", " Analyses de réseaux library(igraph) graph &lt;- graph.data.frame(links,nodes,directed=TRUE) graph &lt;- graph.adjacency(df,mode=&quot;directed&quot;) 5.3 Bases de la théorie Graphe : ensemble dunités (sommets) connectées par une ou plusieurs relations (arêtes) Sommets (noeuds, vertices) : unités Arêtes (liens, edges) : relations Réseaux complets v réseaux personnels (réseaux égo-centrés) # Taille du réseau = nombre de noeuds length(V(graph)) # Nombre de liens length(E(graph)) 5.3.1 Matrices Ou comment stocker ses données avant de les traiter. dadjacence matrice symétrique avec liens non-orientés (du coup liens réciproques) Carrée \\(n* n\\) Edge list : chaque paire de noeuds connectés sur une ligne dune table Node list : chaque ligne représente les liens dun noeud vers tous les autres 5.3.2 Liens Orientés Réciproques Non-orientés 5.4 Structures locales Ou comment un réseau sorganise. Noeuds isolés Dyades Réciprocité Triades (liens orientés) Empty One-edge Two-path Triangle Triades (liens non-orientés) Intransitive : liens bilatéraux uniquement Transitive : lami de mon ami est mon ami Trois-cycles : forme déchange généralisé Clique : sous-ensemble de noeuds où toutes les paires de noeuds existants sont connectés. Modularité : mesure segmentation dun réseau en modules. Réseau à modularité élevée a densité élevée entre les noeusd qui font partie dun même module, densité faible entre noeuds appartenant à modules différents. # Trois algorithmes de modularité wtc &lt;- walktrap.community(graph) grd &lt;- fastgreedy.community(graph) spn &lt;- spinglass.community(graph) # Indicateur de modularité pour le réseau modularity(graph, membership(wtc)) modularity(graph, membership(grd)) modularity(graph, membership(spn)) 5.5 Connectivité Chaîne/walk : parcours sur graphe non orienté allant dun noeud à un autre en empruntant des arêtes (liens) Chemin : chaîne mais pour un graphe orienté Chaîne/chemin élementaire (path) si chaque noeud y apparaît au plus une fois. Géodésique (geodesic) : chaine/chemin élémentaire la/le plus court(e) (shortest path) entre deux noeuds. Cycle : départ et arrivée de la chaine/chemin élémentaire est le même noeud. Graphe connexe (connected) : chemin ou chaîne entre toute paire de noeuds. Composante : sous-graphe maximalement connecté. Distance (géodésique) : nb de pas (plus courts chemins) entre un noeud et lautre. noeuds connectés ont distance 1 noeuds dans composantes différentes ont distance infinie Diamètre : distance la plus longue entre deux noeuds. Average path length : distance moyenne entre toutes les pairs de noeuds dans un réseau (moins sensible à des outiliers que le diamètre). Eccentricité : distance depuis un noeud de départ vers le noeud le plus loin dans le réseau. Rayon : eccentricité minimale des noeuds. La plus petite distance à laquelle puisse se trouver un noeud de tous les autres (infini si graphe est non connecté) shortest.paths(graph, algorithm=&quot;unweighted&quot;) # Shortest path entre deux noeuds get.shortest.paths(graph, V(graph)[name==&quot;name1&quot;], V(graph)[name==&quot;name2&quot;], mode=&quot;all&quot;, output=&quot;both&quot;) # Distance moyenne entre les noeuds average.path.length(graph) # Diamètre diameter(graph) # Eccentricité eccentricity(graph) # Rayon : eccentricité la plus faible radius(graph) 5.6 Mesures basiques de cohésion Tous les noeuds sont-ils liés entre eux? Quels types de liens existent dans le réseau et dans quelle quantité? Transitivité : \\(\\frac{nombre.triades.transitives}{nombre.triades}\\) égal à 1 si tous les noeuds sont liés à tous les autres noeuds (connectivité complète) Excède rarement 0.2 dans réseaux aléatoires. Souvent compris entre 0.3 et 0.6 dans les réseaux empiriques. Densité : \\(\\frac{nombre.liens.existants}{nb.liens.pouvant.existés}\\) \\(\\frac{L}{(n*(n-1))}\\) liens orientés \\(\\frac{L}{\\frac{(n*(n-1))}{2}}\\) liens non-orientés Coefficient de clustering : mesure de cohésion dans le voisinage dun noeud (combien de mes amis sont amis entre eux). 2 mesures : Mesure locale : on mesure dabord pour chaque noeud i, le \\(Cl_{i}\\) ensuite on prend la moyenne \\(\\sum_{i = 1}^{n}\\)\\(\\frac{Cl_{i}}{n}\\). Tends to 1. Mesure globale : \\(\\sum_{i=1}^{n}\\)\\(\\frac{nombre.liens.existants.entre.amis.de.i}{nombre.liens.possibles.entre.amis.de.i}\\). Tends to 0 =&gt; transitivité. # Transitivité du réseau transitivity(graph) # Transitivité d&#39;un noeud transitivity(graph,type=&quot;local&quot;) # Densité du réseau graph.density(graph) # Nombre d&#39;îles, i.e. clusters clusters(graph) 5.7 Mesures de diversité Tous mes groupes sont-ils représentés proportionnellement dans mon réseau? Deux familles de mesures: proportion (ou pourcentage) dune catégorie sur la totalité hétérogénéité (variance, écart-type, IQV) Indice de diversité de Blau \\(\\in[0;\\frac{k-1}{k}]\\) Une seule catégorie représentée =&gt; toutes les catégories représentées équitablement (utile si plus de 2 catégories - variante de lindice Herfindahl-Hirschmann (HHI)) Indice de variation qualitative, IQV \\(\\in[0;1]\\) Une seule catégorie représentée =&gt; toutes les catégories représentées équitablement (un indice POUR CHAQUE ATTRIBUT dintérêt) get.Blau.index &lt;- function(x, type) { x &lt;- factor(x, levels = type); return(1 - sum(prop.table(table(x))^2))} # Indice de diversité de Blau qualif_blau &lt;- get.Blau.index(as.factor(V(graph)$variable)) # on applique la fonction de l&#39;IB à la variable x qualif_blau # Indice de variation qualitative qualif_iqv = qualif_blau / (1 - (1 / length(levels(as.factor(Proportions$Var1))))) qualif_iqv # IQV de Qualification!!! # HHI qui est égal à 1 - qualif_blau qualif_hhi &lt;- 1 - qualif_blau qualif_hhi 5.8 Mesures de centralité Y a-t-il un noeud ou groupe de noeuds qui a une plus grande importance/qui est le plus relié dans le réseau? Centralité de degré (degree) noeuds les plus actifs (les plus connectées, qui sont liés à un plus grand nombre de noeuds) \\(C_D(i) =\\) \\(\\sum_{j=1}^{n}x_{ij} = \\sum_{j=1}^{n} x_{ji}\\) mesure normalisée: \\(C&#39;_D(i)=\\frac{\\sum_{j=1}^{n}x_{ij}}{n-1}\\) centralité de demi-degré pour graphe orienté. Indicateur de position sociale. Extérieur (outdegree) = nb liens sortants (e.g: demander beaucoup de conseils) Intérieur (indegree) = nb liens entrants (e.g: recevoir beaucoup de demandes de conseils) Centralité dintermédiarité (betweenness) position stratégique, entre différentes parties du réseau (e.g être le lien entre deux parties non connectées) nb de plus courts chemins entre toute paire dacteurs k et j, et on prend ceux qui passent par i \\(C_B(i)=\\)\\(\\sum_{jk}\\)\\(\\frac{s_{kij}}{s_{kj}}\\) Centralité de proximité (closeness). Un peu comme centralité de degré, mais noeuds sont pas aussi centraux. Centralité de vecteur propre (eigenvector). Être connecté aux autres noeuds les plus connectés. Centralité dans un réseau : se calcule pour chaque noeud dans un réseau (devient un attribut du noeud) [NB: soit centra de proxi, soit centra de degré, soit intermédiarité, etc]. Dans quelle mesure le réseau est dominé par un noeud central (ou peu de noeuds centraux) ? On compare la centralité du noeud le plus central à la centralité des autres noeuds. Au niveau du réseau dans son ensemble, on peut regarder: La distribution des centralités des noeuds; Des indicateurs de centralisation agrégés. mesure de centralisation de Freeman # Centralité de degré degree(graph,mode=&quot;all&quot;) degree(graph,mode=&quot;in&quot;) degree(graph,mode=&quot;out&quot;) # Centralité d&#39;intermédiarité betweenness(graph,directed=TRUE) # Centralité de proximité # il faut d&#39;abord enlever les noeuds isolés, sinon le calcul ne marche pas Isolated = which(degree(graph)==0) graph2 = delete.vertices(graph, Isolated) # on construit un nouveau graphe en enlevant Isolated # on calcule la proximité sur ce graphe close_graph &lt;- closeness(graph2, mode=&#39;all&#39;, normalized = FALSE) # pour obtenir la valeur normalisée, la commande est : close_graph2 &lt;- closeness(graph2, mode=&#39;all&#39;, normalized = TRUE) # Centralité de vecteur propre eigen_centrality(graph, scale = TRUE, weights = NULL) "]]
