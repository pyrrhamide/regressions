[["reg-log.html", "2 Régressions logistiques 2.1 Régression logistique dichotomique 2.2 Régression logistique polytomique 2.3 Odds ratio", " 2 Régressions logistiques \\[logit(p) = log(\\frac{p}{1-p}) = \\beta_0 + \\sum_{j=1}^n \\beta_j X_{ij}\\] 2.1 Régression logistique dichotomique Pour une raison qui méchappe parce que je suis pas très fraîche, et tout simplement parce que je ne sais pas, on nutilise pas le modèle de régression linéaire de probabilité mais plutôt le modèle de régression logistique dichotomique. Pour les coefficients, on parlera de leffet du logit de probabilité que lévènement \\(y=1\\) se passe. On lance dabord le modèle de régression logistique à effets principaux, ou modèle de lindépendance : model_6 &lt;- glm(var_dep_dicho ~ var_indep1 + var_indep2 + var_indep3, data = d, weights = poids, family=binomial) Petite note sur le modèle de lindépendance totale : cest le modèle dans lequel tu balances tes variables explicatives sans interaction ou association, pour vérifier si les variables sont indépendantes entre elles, càd si  toutes choses égales par ailleurs  elles expliquent le phénomène à elles seules. Cependant, en socio, cest inimaginable que la classe sociale et le sexe agissent indépendamment lun de lautre, cest pour cette raison quon choisirait dintéragir ces variables entre elles. Pour vérifier si les variables sont indépendantes, tu regardes la residual deviance : si cest un nb énorme1, direction interaction-ville. # On met le modèle précédent à jour, en ajoutant des interactions. # pour une unique interaction model_7 &lt;- update(model_6, . ~ . + var_indep1*var_indep2) # pour interagir toutes les modalités de toutes les variables entre elles (interaction d&#39;ordre 2) model_8 &lt;- glm(var_dep_dicho ~ (var_indep1 + var_indep2 + var_indep3)^2, data = d, weights = poids, family=binomial) # pour interagir var_indep3 avec var_indep1 et var_indep2 [plus rapide que d&#39;écrire individuellement chaque interaction] model_9 &lt;- glm(var_dep_dicho ~ (var_indep1 + var_indep2)*var_indep3, data = d, weights = poids, family=binomial) # le modèle saturé (interaction d&#39;ordre 3 - toutes les interactions inférieures seront automatiquement là) model_10 &lt;- glm(var_dep_dicho ~ var_indep1*var_indep2*var_indep3,d,binomial) Le coefficient dinteraction sadditionne aux coefficients de base des catégories qui correspondent à ce nouveau coef. Par exemple, on interagit le sexe et le niveau de diplôme. Tu obtiens les résultats suivants : - \\(\\beta_1\\) le coefficient pour sexe=1 (par exemple les filles); - \\(\\beta_2\\) le coefficient du niveau de diplôme=1 (par exemple ceux qui ont obtenu une licence); - \\(\\beta_3\\) le coefficient de linteraction entre les deux modalités. Pour obtenir le vrai effet de lobtention de la licence chez les filles sur la \\(var\\_dep\\), tu additionnes ces trois coefficients. Tu ne peux pas additionner le coefficient dinteraction pour les garçons avec licence, ou les filles sans licence. On veut voir si lajout de ces interactions est statistiquement significative (il y a la méthode qui suit, et une autre quon a vu plus tard). On effectue un test statistique sur linteraction, qui est distribué comme une loi du khi-deux, sur la différence de vraisemblance entre les modèles dindépendance et dinteraction. test &lt;- 2*(logLik(model_7)-logLik(model_6)) [1] # Entre ces deux modèles, il n&#39;y a qu&#39;une variable/modalité en plus, donc le degré de liberté est de 1 (je sais plus pourquoi). 1-pchisq(test,1) # (test,1), 1 étant le ddl. On obtient la probabilité que linteraction soit due au hasard. Si la valeur est inférieure ou égale à 0.10, on peut rejeter lhypothèse que linteraction soit due au hasard. 2.2 Régression logistique polytomique On a vu la régression logistique dichotomique. Mais pour une variable à expliquer qui contient plus de 2 modalités, on utilise le modèle de régression logistique polytomique. Imaginons que tu ais une variable \\(n\\) à expliquer avec des modalités 1 (modalité de référence), 2 et 3, et une variable \\(m\\) explicative avec des modalités A (modalité de ref), B et C. Tu interpréteras un coefficient ainsi : toutes choses égales par ailleurs, le logit de probabilité que lévènement \\(y=2\\) se produise, par rapport à lévènement \\(y=1\\), pour le groupe B augmente/diminue par rapport au groupe A. Cest une phrase assez dégueulasse. Toutefois cest un modèle de régression sur lequel on ne sest pas attardés lannée dernière donc je nen dis pas plus. Voici la commande pour lancer le modèle. model_10 &lt;- multinom(var_dep_poly ~ var_indep1 + var_indep2 + var_indep3, data=d, weights=poids) 2.3 Odds ratio Passons à un truc dont on parle beaucoup en classe : les odds ratio. Les coefficients dune régression logistique ne sont pas évidents à interpréter (dans le sens où cest long de dire le logit de probabilité et que humainement, cest moche). On passe donc les coefficients logit par la fonction exponentielle, ce qui nous donne les odds ratio (OR). Un OR est la chance quun évènement \\(y=1\\) se passe pour une condition B, par rapport à ce que cet évènement \\(y=1\\) se passe pour une condition A (condition de ref). LOR est compris entre \\([0;+\\infty[\\). Pour un OR compris entre 0 et 1, la chance que le truc se passe pour un groupe B est en fait moindre que la chance quil se passe pour le groupe A, mais on dira quand même lévènement a 0.14 fois plus de chance de se passer pour le groupe B que pour le groupe A. Pour obtenir les coefficients de la régression en OR, on utilise la commande suivante : exp(model_7$coefficients) # ou model_7$coefficients %&gt;% exp # au choix Les odds ratios se calculent également à partir des effectifs attendus, estimés par le modèle (model$fitted.values). Imaginons quon ait le tableau de contingence suivant, avec les effectifs estimés: Je suis à lheure Je suis en retard Il y a une feuille sur les rails \\(m_{1,1}\\) \\(m_{1,2}\\) RAS sur les rails \\(m_{2,1}\\) \\(m_{2,2}\\) La formule pour calculer lOR est la suivante: \\[ OR = \\frac{m_{1,1} \\times m_{2,2}}{m_{2,1} \\times m_{1,2}} \\] Là jai calculé lodds ratio/la chance que je sois à lheure sachant quil y a une feuille sur les rails. plus sérieusement, si la valeur dépasse largement le seuil critique de la distribution du khi-deux (selon les degrés de libertés of course), on rejette lhypothèse de lindépendance statistique entre les variables. Vu quil reste quand même un pâté de déviance à expliquer, on introduit des interactions dans le modèle de lindépendance totale. "]]
