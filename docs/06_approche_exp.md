# Mod√©lisation et identification causale, vol. 2 {#mod-id2}

_Copie des diapositives du cours d'Olivier Godechot._




```r
library(lfe)
library(AER)
library(survival)
library(plm)
library(lmtest)
```

Je mets imm√©diatement les lignes de codes compl√®tes ici. Je recommande d'utiliser la fonction `felm()` du package `lfe` pour toutes les techniques de ce cours, mais il est aussi possible d'utiliser `lm()`, `plm::plm()` ou `AER::ivreg()` pour de petites v√©rifications.

La fonction `felm()` fait tout: les effets fixes, les effets al√©atoires, les variables instrumentales, la clusterisation des erreurs-types...it's the GOAT üêê.

```r
## La syntaxe des commandes principales ##
felm(y ~ x1 + x2 | f1 + f2 | x3 + x4 | clu1 + clu2, data, weights, ...)
# soit
felm(var_dep ~ vars_indep | vars_effet_fixe | vars_instrumentales | vars_cluster_se, data, weights, ...)
# si on veut seulement clusteriser les erreurs-types, on remplace
# vars_effet_fixe et/ou vars_instrumentales par 0
felm(y ~ x1+x2 |0|0|clu1+clu2, data, weights, ...)

# Pour les variables instrumentales - plus d√©taill√© plus tard
ivreg(y ~ x1 + x2 | z1 + z2, data, weights, ...)
# soit
ivreg(var_dep ~ var_endo + vars_indep | vars_exo_inst, data, weights, ...)

# Pour les donn√©es de panel/effets fixes et tout √ßa
plm(y ~ x1 + x2, index=c("var_indiv","var_temps"), data, model = "pooling")
  # voir la documentation pour les autres "model" et √©galement les "effect".
```

## Approches exp√©rimentales

Groupe trait√© v groupe de contr√¥le.

Pour conna√Ætre l'effet du traitement, groupe 'trait√©' diff√®re du groupe de contr√¥le seulement du traitement.

4 m√©thodes autour de cette id√©e:

1. Exp√©riences al√©atoires contr√¥l√©es
2. Exp√©riences naturelles
3. Diff√©rences de diff√©rences
4. R√©gression par discontinuit√©

### Exp√©riences al√©atoires contr√¥l√©es
2 exemples d'exp√©riences al√©atoires contr√¥l√©es:

* Exp√©rience √† essais randomis√©s contr√¥l√©s (*randomised controlled trials (RCT) experiments*)
* Exp√©riences par questionnaire (*randomised survey experiment*)

On prend un groupe uniforme, qui rempli les m√™mes caract√©ristiques, √† qui on applique un ou des traitements diff√©rents pour voir si les r√©sultats sur une variable √† expliquer diff√®rent.

Il y a du soleil. **Al√©atoirement**, on soumet les individus √† des traitements diff√©rents (c'est la ventilation al√©atoire): une partie du groupe se met √† l'ombre, une autre applique de la cr√®me solaire, et une autre ne fait rien (c'est le groupe de contr√¥le - ind√©pendance du traitement). Avec cette exp√©rience, quel est le traitement qui r√©duit le plus les chances d'attraper un coup de soleil ?

**Pourquoi l'exp√©rience randomis√©e ?**

* Ventilation al√©atoire assure que toutes les caract√©ristiques des individus (√† la fois observ√©es et surtout inobserv√©es) vont √™tre ventil√©es de mani√®re √©quiprobable dans les groupes trait√©s ou de contr√¥le.
* L'estimation n'est plus biais√©e par une variable confondante (h√©t√©rog√©n√©it√© inobserv√©e)
* Simplification consid√©rable de la statistique
  * intensit√© indiqu√©e par la diff√©rence (ou le rapport) des moyennes
  * significativit√© test de diff√©rence de moyennes ou de proportions [pr√©ciser le.s tests en question]
* Exp√©rience al√©atoire versus √©chantillon al√©atoire
  * √©chantillon al√©atoire: √©tablir des statistiques repr√©sentatives d'une population $\rightarrow$ validit√© externe [d√©finir ce que c'est].
  * exp√©rience al√©atoire: ventilation al√©atoire d'un √©chantillon $\rightarrow$ validit√© interne [d√©finir].

**L'exp√©rience et ses aveugles**

* Simple aveugle: le patient ne sait pas dans quel groupe il est (trait√© ou placebo)
* Double aveugle: le patient et la personne qui administre le traitement ne savent pas dans quel groupe se trouve le patient
* Triple aveugle: le patient, la personne qui administre le traitement et le statisticien ne savent pas dans quel groupe se trouve le patient.

L'exp√©rience al√©atoire en sciences sociales est rarement une exp√©rience avec placebo et en aveugle. Le placebo, qui doit avoir la forme, le go√ªt, etc. du placebo, n'existe pas toujours [trouver exemple]. Il y a souvent 2 groupes: un qui fait l'objet d'une intervention et un qui ne re√ßoit rien. Il importe alors d'√™tre vigilent √† faire une analyse en intention de traiter (*intention to treat*) plut√¥t que traitement r√©alis√© (*treatment on treated*).

[parler des limites techniques et conceptuelles?]

### Exp√©riences naturelles

* Situation "naturelle" qui ressemble √† une situation exp√©rimentale (ventilation al√©atoire ou quasi-al√©atoire d'une population entre groupe trait√© et groupe de contr√¥le) sans avoir √©t√© construite √† des fins exp√©rimentales.
* Tirages au sort comme proc√©dure d'allocation (e.g. jur√©s en tribunal, distribution dans les chambres d'internat, r√©partition entre ceux qui ont d√ª pr√©senter leur probl√©matique de m√©moire le jour 1 et le jour 2)
* Autres exemples : jeux al√©atoires et loteries, ph√©nom√®ne al√©atoires ou quasi al√©atoires (sexe de l'enfant/mois de naissance), recrutement acad√©mique...

[EXEMPLE!!!]

### Diff√©rences-de-diff√©rences (*differences-in-differences*)

On reprend l'opposition groupe trait√© versus groupe de contr√¥le des exp√©riences contr√¥l√©es. Toutefois, on n'est pas s√ªr que les groupes de contr√¥les soient vraiment similaires en tout point except√© le traitement. On va faire une hypoth√®se plus faible: la diff√©rence entre traitement et contr√¥le est constante dans le temps.

  * diff√©rence pr√©traitement est la diff√©rence li√©e aux "inobservables"
  * diff√©rence post-traitement est la diff√©rence li√©e aux "inobservables" + effet causal
  * diff√©rence de diff√©rence est l'effet causal (diff post - diff pr√©)

Diff√©rence "standard" :
$$Trait√© - Contr√¥le \\ T_1 - C_1$$
Diff√©rence de diff√©rence est l'estimation :
$$DiD = (Trait√©_{post}-Trait√©_{ant√©})-(Contr√¥le_{post}-Contr√¥le_{ant√©}) \\ DiD = (T_1-T_0)-(C_1-C_0)$$

Notations classiques :\
- $T_1=\mu_{11}$ ; $T_0=\mu_{10}$ ; $C_1=\mu_{01}$ ; $C_0=\mu_{00}$\
- Diff-in-Diff = $(\mu_{11}-\mu_{01})-(\mu_{10}-\mu_{00})$

**Estimations √©conom√©triques**\
Quand on a un panel :\
- on mesure sur les m√™mes individus, l'avant et l'apr√®s,\
- on estime l'√©volution,\
- $\Delta y_i = \beta_0 + \beta_1 GT + \epsilon_i$ ou GT est le groupe trait√©,\
  - $\Delta y_i$ est l'√©volution/la variation de $y_i$
  - $\beta_0$ est l'intercept [nom sp√©cial en DiD?]
  - $\beta_1$ est l'estimateur DiD.
  - $\epsilon_i$ est le terme d'erreur [distribution sp√©ciale?]

Quand on n'a pas de panel :\
- les individus avant et apr√®s ne sont pas les m√™mes,\
- $y_{it} = \beta_0 + \beta_1 GT + \beta_2 t + \beta_3 t \times GT + \epsilon_{it}$,\
- $\beta_3$ est l'estimateur DiD.

**Port√©es et limites**

* Hypoth√®ses fortes:
  * la diff√©rence entre le traitement et le contr√¥le serait rest√©e constante en l'absence de traitement.
  * ou redit autrement, la diff√©rence de diff√©rence est uniquement due au "traitement" et non √† un autre changement intervenu dans le groupe trait√© entre la p√©riode 1 et 2.
* Si on dispose de plus de deux p√©riodes, on peut faire une v√©rification graphique.

### R√©gression par discontinuit√© (*Regression discontinuity design*)

Les groupes sont ventil√©s pour recevoir ou non un traitement en fonction d'un seuil sur une variable mesurable (continue). Par exemple, les personnes qui sont arr√™t√©es au-del√† d'un seuil d'alcool dans le sang ont l'obligation de suivre un traitement, et les groupes au-dessous de ce seuil servent de groupe de comparaison (groupe de contr√¥le). L'effet est mesur√© au niveau de la discontinuit√© entre le groupe trait√© et le groupe de contr√¥le (on ne fait pas la diff√©rence de moyenne entre deux groupes).

**Conditions d'applications**

Le seuil est exog√®ne, non manipulable, et d√©clenche les actions:

* majorit√© absolue $\rightarrow$ effet de l'√©lection
* rang du dernier poste offert au concours $\rightarrow$ effet de l'√©cole
* seuil de d√©clenchement d'une mesure sociale ou fiscale $\rightarrow$ effet de la politique, etc...

**Avantages et d√©savantages**

Avantages: quand c'est bien effectu√©, la r√©gression par discontinuit√© permet une estimation non biais√©e du traitement.

D√©savantages:

* la puissance statistique est bien moindre que dans des essais randomis√©s contr√¥l√©s portant sur le m√™me effectif. L'attention √† la puissance statistique est cruciale.
* les effets sont sans biais uniquement si la forme fonctionnelle entre la variable d'assignation et la variable de r√©sultat est bien mod√©lis√©e, y compris:
  * des relations non-lin√©aires (augmentation - plateau - augmentation)
  * des interactions (pente coef 1 - seuil - pente coef 2)

**Estimations √©conom√©triques**\
Le mod√®le lin√©aire simple (premi√®res estimations)\
- $y_i = \beta_0 + \beta_1 x + \beta_2 (x>seuil) + \epsilon_i$,\
- L'effet causal est mesur√© par $\beta_2$,\
- Limite suppose que la forme fonctionnelle est la m√™me de part et d'autre du seuil (en gros, que le coefficient de la pente soit pas trop diff√©rent √† gauche et √† droite de la discontinuit√©).

Le mod√®le lin√©aire avec changement de pente\
- $y_i = \beta_0 + \beta_1 x + \beta_2 (x>seuil) + \beta_3x \times (x>seuil) + \epsilon_i$\
- l'effet causal est mesur√© par $\beta_2$.
- diff√©rence avec mod√®le lin√©aire simple: on interagit $x$ pr√©-seuil et post-seuil.

Le mod√®le lin√©aire avec changement de forme\
- attention de bien centrer la variable $x$ autour du seuil ! $x' = x-seuil$,\
- $y_i = \beta_0 + \beta_1 x' + \beta_2 x^{'2} + \beta_3(x'>0) + \beta_4x' \times (x'>0) + \beta_5 x^{'2} \times (x'>0) + \epsilon_i$,\
- l'effet causal est mesur√© par $\beta_3$.


```r
# Regression discontinuity design - je recommande de regarder directement le code du prof et de lancer les commandes.

# recentrage de la variable autour du seuil
d$var_cont_cent <- d$var_continue - valeur_seuil_au_choix # commande parmi plein d'autres, l√† c'est toi qui prend l'initiative

pr1 <- lm(var_dep ~ var_continue+I(var_continue>=valeur_seuil_au_choix),data=d)
# suppose que pente est la m√™me √† gauche et √† droite du seuil

pr1 <- lm(var_dep ~ var_cont_cent+I(var_cont_cent>=0),data=d)

pr2 <- lm(var_dep ~ var_continue+I(var_continue>=valeur_seuil_au_choix)+
          I((var_continue>=valeur_seuil_au_choix)*var_continue),data=d)

# pour cacher les points extr√™mes de la base (pour garder la lin√©arit√©)
pr2b <- lm(var_dep ~ var_continue+I(var_continue>=valeur_seuil_au_choix)+
            I((var_continue>=valeur_seuil_au_choix)*var_continue),
           data=d[d$var_continue>=valeur1 & d$var_continue<=valeur2,])
# pr2 et pr2b supposent que l'effet est lin√©aire des deux cot√©s du seuil


pr3 <- lm(var_dep ~ var_cont_cent+
            I(var_cont_cent>=0)+
            I((var_cont_cent>=0)*var_cont_cent)+
            I((var_cont_cent>=0)*var_cont_cent2),data=d)
```

## Variables instrumentales
Violation de la 6√®me hypoth√®se des MCO ($Cov(x_i,\epsilon_i \neq 0)$ absence de corr√©lation entre les variables explicatives et le r√©sidu) $\Rightarrow$ *endog√©n√©it√©*. Pb endog√©n√©it√© peut conduire √† se tromper dans l'interpr√©tation des param√®tres. Variables instrumentales comme technique de correction.

3 probl√®mes et leurs effets sur les param√®tres:

* Erreur de mesure d'une variable explicative: sous-estimation de la valeur absolue du param√®tre $\beta_i$.
* Variable omise ou h√©t√©rog√©n√©it√© inobserv√©e (corr√©l√©e √† la variable d√©pendante et √† une autre variable explicative): sur/sous-estimation de la valeur absolue du param√®tre.
* Simultan√©it√© (variable explicative d√©pend de la variable expliqu√©e): effet plus complexe. Pas d'intuition √©vidente.

Solution $\Rightarrow$ variable instrumentale: trouver une variable instrumentale exog√®ne qui impacte ma variable expliqu√©e $y_i$ uniquement par l'interm√©diaire de son effet sur la variable explicative $x_i$ suspecte d'endog√©n√©it√©.
$$ instrument \rightarrow var\_endo \rightarrow var\_dep$$

Sachant que $cov(x_{endo},\epsilon) \neq 0$, on introduit une variable instrumentale ($z_{inst}$) telle que:

* $cov(z_{inst},x_{endo}) \neq 0$, et
* $cov(z_{inst},\epsilon) = 0$

Vrai mod√®le^[Diff√©rent du mod√®le *th√©orique*.]: $y = a_{vrai} + b_{vrai} x_{endo} + c_{vrai} x_2 + \epsilon$ avec $cov(x_{endo},\epsilon) \neq 0$.

**Premi√®re √©tape**: on r√©gresse la variable endog√®ne √† la fois sur l'instrument et sur les autres variables explicatives. NB: on met toutes les variables explicatives m√™me non pertinentes en premi√®re √©tape.
$$x_{endo} = a_0 + a_1 z_{inst} + a_2 x_2 + \epsilon_{prem}$$

On r√©cup√®re de cette premi√®re r√©gression $x'_{endo}$, la pr√©diction de la variable endog√®ne $x_{endo}$:
$$x'_{endo} = a_0 + a_1 z_{inst} + a_2 x_2 = x_{endo} - \epsilon_{prem}$$

**Deuxi√®me √©tape**: on introduit cette pr√©diction dans la r√©gression √† la place $x_{endo}$.
$$y = a_{est} + b_{est} x'_{endo} + c_{est} x_2 + \epsilon_{deux}$$

Comme $z_{inst}$ et $x_2$ ne sont pas corr√©l√©s avec le r√©sidu $\epsilon$, alors $x'_{endo}$ n'est plus corr√©l√© avec $\epsilon$, l'estimateur des variables instrumentales permet d'estimer sans biais $b_{vrai}$ (et le reste).


```r
## 1√®re fa√ßon de proc√©der ##
# MCO "na√Øve"
mco <- lm(y ~ x_endo + x1 + x2, data, weights, ...)

# Forme r√©duite - impact des instruments sur variable d√©pendante (facultatif)
fr <- lm(y ~ z1 + z2, data, weights, ...)

# Premi√®re √©tape: regression endogene sur autres variables ind√©pendantes et instruments
pe <- lm(x_endo ~ x1 + x2 + z1 + z2, data, weights, ...)

# Deuxi√®me √©tape: on introduit la prediction dans la r√©gression "na√Øve"
mco2 <- lm(y ~ pe$fitted.values + x1 + x2, data, weights, ...)

## Deuxi√®me fa√ßon de proc√©der ##
# R√©gression variable instrumentale directe, sans premi√®re √©tape
z <- ivreg(y ~ x_endo + x1 + x2 | z1 + z2, data, weights, ...)

# Pour voir les coefficients de la premi√®re √©tape
z$coefficients1

# Documentation officielle [v√©rifier si dans cours]:
# Note that exogenous regressors have to be included as instruments for themselves. For example, if there is one exogenous regressor ex and one endogenous regressor en with instrument in, the appropriate formula would be
ivreg(y ~ ex + en | ex + in)

## Troisi√®me fa√ßon de proc√©der ##
# R√©gression avec instruments, sans effet fixe et sans clusterisation
felm(y ~ x_endo + x1 + x2 |0| z1+ z2 |0, data, weights, ...)
```

## Econom√©trie des panels
L'√©conom√©trie des panels rend visible et permet de traiter deux probl√®mes classiques :

1. L'autocorr√©lation des r√©sidus,
2. L'h√©t√©rog√©n√©it√© inobserv√©e.

**Autocorr√©lation des r√©sidus**

* $Cov(\epsilon_{it},\epsilon_{it+1}) = 0$ ?
* Si je suis sous-pay√©e √† la date $t$, je le serai sans doute √† la date $t+1$.

**H√©t√©rog√©n√©it√© inobserv√©e**

* Si $\epsilon_{it} = v.inobs + e$ et $cov(x_{ik},inobs) \neq 0 \Rightarrow$ biais.
* Le r√©sidu $\epsilon_{it}$ peut √™tre r√©√©crit de la mani√®re suivante: $\epsilon_{it} = \alpha_i + e_{it}$, comme la somme d'une erreur individuelle constante $\alpha_i$, et $e_{it}$ une erreur temporaire.
* $\alpha_i$ peut √™tre vu comme d√©termin√© par les variables inobserv√©es *constantes dans le temps*.
* Question: peut-on dire que dans notre vrai mod√®le cette erreur constante $\alpha_i$ par individu est ind√©pendante des variables explicatives, soit $cov(\alpha_i,x_k) = 0$ ?
  * Oui $\rightarrow$ estimation *pooling* ou al√©atoire est la bonne.
  * Non $\rightarrow$ hypoth√®se des MCO $cov(\epsilon_i,x_k) = 0$ n'est pas respect√©e. Le mod√®le des MCO n'est pas consistant pour estimer les $\beta \rightarrow$ mod√®les √† effets fixes ou en diff√©rences premi√®res.

### Le mod√®le homog√®ne, ou *pooled*

ou comment r√©soudre le probl√®me d'autocorr√©lation des r√©sidus.

Mod√®le estim√© par les MCO: $y_{it}=\beta_0+\beta_1 x_{it}+...+\beta_k x_{kit} + \epsilon_{it}$

Le mod√®le *pooled/pooling* ou mod√®le homog√®ne suppose que tous les r√©sidus ont la m√™me variance et qu'il n'y a pas d'autocorr√©lation des r√©sidus.

```r
lm(y ~ x1 + x2, data)
# ou
plm(y ~ x1 + x2, data, index=c("individu","temps"), model = "pooling")
```

**La r√©solution du probl√®me d'autocorr√©lation des r√©sidus**

Deux possibilit√©s:

1. Corriger la matrice de variance covariance:
    * estimateur sandwich de Huber-White/ *robust standard errors* : on corrige les √©cart-types pour tenir compte de l'h√©t√©rosc√©dasticit√© des r√©sidus (mais pas de l'autocorr√©lation) $\rightarrow$ h√©t√©rog√©n√©it√© des variances des r√©sidus.
    * correction par cluster / *robust clustered standard errors* : on corrige les √©cart-types pour tenir compte √† la fois de l'h√©t√©rosc√©dasticit√© des r√©sidus et de leur autocorr√©lation par cluster (individus, nations, famille...) $\rightarrow$ h√©t√©rog√©n√©it√© des variances des r√©sidus + r√©sidus clusteris√©s donc homog√©n√©it√© des variances des r√©sidus au sein des groupes.
2. Mod√©liser l'erreur comme la combinaison d'une erreur individuelle fixe et d'une erreur temporelle $\Rightarrow$ mod√®le √† effet al√©atoire (*random effect*).

```r
# L√† il y a une flop√©e de m√©thodes possibles pour corriger les √©cart-types, mais la mani√®re la plus simple est d'utiliser directement la fonction felm() en pr√©cisant la variable de groupe pour obtenir des erreurs-types robustes clusteris√©es.
# Utilise felm(), jdcjdr.
felm(y ~ x1 + x2 |0|0| var_cluster_se, data)
```

### Les mod√®les √† effet al√©atoire
On estime le mod√®le suivant:
$$y_{it} = \beta_0 + \beta_i x_{it} + \alpha_i + \epsilon_{it}$$

* Deux termes al√©atoires $\alpha_i$ et $\epsilon_{it}$ qui ont chacun une loi de distribution propre.
* La technique d'estimation est celle des moindres carr√©s g√©n√©ralis√©s.
* L'avantage de ce mod√®le est de permettre une d√©composition de la variance des r√©sidus en un facteur individuel (i.e. *between*, et le cas √©ch√©ant un facteur temporel) et un facteur idiosyncrasique [big words].

```r
plm(y ~ x1 + x2, data, index, model = "random")
```

### Le probl√®me d'h√©t√©rog√©n√©it√© inobserv√©e

Mod√®le √† effet al√©atoire :
$$y_{it} = \beta_0 + \beta_i x_{it} + \alpha_i + \epsilon_{it}$$

* Si $cov(x_{kit},\alpha_i) = 0$, RAS.
* Mais l'erreur individuelle $\alpha_i$ peut √™tre vue comme le produit de l'ensemble des variables inobservables invariantes dans le temps. Il n'est pas impossible que ces variables inobservables soient corr√©l√©es avec les observables.
* Plut√¥t que de mod√©liser les $\alpha_i$ par un effet al√©atoire, on peut les mod√©liser par un effet fixe.

#### Mod√®le √† effets fixes (*fixed effects*)

* Moindre carr√© √† variables dichotomiques : *Least square dummy variables* ou LSDV. Introduire une variable dichotomique $\alpha_i$ par individu, possible uniquement si le nombre d'individus est petit (<1000).
* Mod√®le "*within*"* : mod√®le (sans constante) o√π l'on centre chaque variable (explicative ou expliqu√©e), c√†d o√π l'on calcule l'√©cart √† la moyenne de la variable pour l'individu.

$$(y_{it} - \bar y_i) = \beta_i (x_{it} - \bar x_i) + (\epsilon_{it} - \bar \epsilon_i)$$

```r
# Estimation des effets fixes

## Avec les effets fixes ##
lm(y ~ factor(var_indiv)+x1+x2, data)

## Avec l'estimateur within et le pkg plm ##
plm(y ~ x1 + x2, index, model = "within", data)

## Avec l'estimateur within et le pkg lfe ##
felm(y ~ x1 + x2 | var_indiv, data)
# en clusterisant les erreurs types par individu
felm(y ~ x1 + x2 | var_indiv |0| var_indiv, data)
```

**Deux effets fixes: groupes et temps**

On peut introduire un effet fixe par unit√© de groupe (e.g. individu, pays, etc.) et un effet fixe par unit√© de temps.

La conjoncture commune captur√©e par l'effet fixe temps:

* Tout avec des variables dichotomiques^[A √©viter car prend beaucoup de place et de m√©moire sur la console R.]:

$$y_{it}=\beta_i X_{it} + \alpha_i + \delta_t + \epsilon_{it}$$

* *Within* + variables dichotomiques de temps.

```r
plm(y ~ x1 + x2 + factor(var_temps), index, model="within", data)
```
* *Two ways within* (formule pour panel cylindr√©s)

```r
plm(y ~ x1 + x2, index, model="within", effect="twoways", data) # tr√®s lent
```

#### Effets fixes ou effets al√©atoires ?

Comment choisir?

Test de Hausman: on regarde si l'estimation par effets fixes produit des r√©sultats significativement diff√©rents d'un mod√®le √† effets al√©atoires.

* Si le test de Hausman est significatif, on privil√©giera les effets fixes.
* Si le test de Hausman n'est pas significatif, on privil√©giera les effets al√©atoires.


```r
regfe <- plm(y ~ x1 + x2, data, index, model = "within")
regre <- plm(y ~ x1 + x2, data, index, model = "random")

phtest(regfe, regre)
# p-value significative -> effets fixes.
# p-value non significative -> effets al√©atoires.
```

#### Mod√®les en diff√©rences premi√®res (*first difference*)

Expliquer les √©volutions par les √©volutions (e.g diff√©rence revenu entre 1 ann√©e, puis 2, puis 5, etc...)
$$ (y_{it} - y_{it-1})=\beta_i (x_{it} - x_{it-1}) + (\epsilon_{it} - \epsilon_{it-1})$$
Le choix du retard:

* $[t,t-1] \rightarrow$ on se focalise sur des variations de court terme,
* $[t,t-k] \rightarrow$ variations de plus long terme, mais perte d'effectifs et de puissance.

Diff√©rence entre effets fixes & diff√©rences premi√®res:

* panel √† deux p√©riodes: mod√®les √©quivalents (uniquement lorsque le mod√®le *within* comporte aussi un effet fixe temps).
* panel √† plusieurs p√©riodes: le mod√®le √† effets fixes est une moyenne de variations de courtes et de longues p√©riodes.

```r
plm(y ~ x1 + x2, index, model = "fd", data)
```

**Effets fixes et diff√©rences premi√®res. Remarques**

* Double effet: r√©duction du probl√®me d'autocorr√©lation et suppression du probl√®me d'h√©t√©rog√©n√©it√© inobserv√©e invariante dans le temps.
* Interpr√©tation: les √©volutions expliquent les √©volutions.
* LSDV: variables dichotomiques en tr√®s grand nombre (quand on les estime) $\Rightarrow$ on n'imprime g√©n√©ralement pas les r√©sultats.
* Disparition de la constante en effets fixes mais pas en diff√©rences premi√®res.

* **Disparition de toutes les variables constantes dans le temps** $\Rightarrow$ effet contenu dans les variables dichotomiques individuelles.
    * ex: immigration.
    * Parfois, les variables pr√©sum√©es constantes se maintiennent en raison de points aberrants:
        * incoh√©rence de d√©claration d'une vague √† l'autre,
        * changement de sexe,
        * dipl√¥mes tardifs...
* On peut les introduire malgr√© tout en les croisant avec une variable temporelle. L'interpr√©tation reste en terme d'√©volution.

### Se concentrer sur la variance interindividuelle et √©liminer la variance intra-individuelle

**Etudier la variance interindividuelle**

* Le mod√®le √† effets fixes ou *within* permet d'√©tudier les √©volutions intra-individuelles.
* La r√©gression homog√®ne (*pooled*) ou celles √† effets al√©atoires sont deux mani√®res d'analyser une combinaison de variations intra-individuelles et interindividuelles.
* Peut-on √©tudier les variations strictement interindividuelles? Oui, de deux fa√ßons:
    * R√©gression toute simple sur une seule p√©riode.
    * R√©gression *between*.
    
#### R√©gression *between*

R√©gression o√π l'on explique la moyenne par individu de la variable expliqu√©e par les moyennes par individu des variables explicatives.
$$\bar y = \beta_0 + \beta_1 \bar x_{1i} + ... + \beta_k \bar x_{ki} + \bar \epsilon_i$$

Cette r√©gression informe sur la variation interindividuelle. Elle peut √™tre consid√©r√©e comme la bonne r√©gression:

* Si la variation intra-individuelle dans le temps est n√©gligeable,
* Si les individus qui connaissent des variations intra-individuelles sont non repr√©sentatifs.


```r
plm(y ~ x1 + x2, index, model = "between", data)
```

### Limites des effets fixes

* On estime les effets sur les individus qui connaissent des √©volutions.
    * Si $y_i$ ne change pas en fonction de $t$, alors $y_i$ captur√© par l‚Äôeffet fixe $a_i$.
    * Ces √©volutions, surtout sur des variables explicatives qualitatives, peuvent √™tre estim√©es sur des individus rares et tr√®s singuliers : biais de s√©lection
    * Les variables explicatives du changement peuvent √™tre aussi tr√®s singuli√®res
        * Ex extr√™me: changement de sexe. 
        Cela revient √† consid√©rer que la diff√©rence de r√©sultats entre les sexes est estim√©e par l‚Äô√©volution de r√©sultat pour ceux qui changent de sexe
        * Ex classique: promotion non-cadre $\rightarrow$ cadre
    * Les effets fixes reviennent √† consid√©rer que les √©volutions estim√©es sur les gens qui changent sont repr√©sentatives des diff√©rence d‚Äô√©tat entre gens qui changent pas.

* Les effets fixes permettent bien de corriger l‚Äôh√©t√©rog√©n√©it√© inobserv√©e! Mais une partie seulement
    * L‚Äôh√©t√©rog√©n√©it√© inobserv√©e invariante dans le temps...

* Mais...transforment une r√©gression en une r√©gression en √©volution...
    * O√π un facteur d‚Äô√©volution corr√©l√© aux autres peut √™tre inobserv√© et conduire √† biaiser les autres
    * O√π il peut y avoir simultan√©it√© des √©volutions de la variable ind√©pendante et des variables ind√©pendantes
    * $\Rightarrow$ variables instrumentales (si on en trouve)

* Pas de correction de l‚Äôh√©t√©rog√©n√©it√© inobserv√©e qui varie dans le temps‚Ä¶
* Ontologie essentialiste
    * Effet individuel: fonds inchang√©, permanent, toujours le m√™me.
* Les √©volutions expliquent les √©volutions, mais le fixe n'explique pas le changement (sauf sp√©cification contraire).

### Extension logistique

* Probit (effets al√©atoires), Logistique (effets fixes, effets al√©atoires)^[Logit en panel.]
    * NB: mod√®les probit d√©conseill√©s avec des effets fixes.
* Package `pglm`:
    * binomial models (logit and probit), count models (poisson and negbin) and ordered models (logit and probit).
    * Syntaxe (exemple - actuellement, la m√©thode *within* et *between* ne fonctionne pas pour les mod√®les logit et probit avec pglm.)

```r
pglm(y ~ x1 + x2, index, data, family = "binomial", model = "random")
```
    
* Package `survival`:
    * clogit

```r
clogit(y ~ x1 + x2 + strata(var_indiv), data) # je suis pas s√ªre. de toute fa√ßon on n'utilise pas cette m√©thode.
```
    
